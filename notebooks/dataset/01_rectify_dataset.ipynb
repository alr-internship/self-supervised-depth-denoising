{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate Cameras\n",
    "[https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html](https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dataset.dataset_container import DatasetContainer\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_path = Path(\"../../resources\")\n",
    "file_to_calibrate = Path(\"c_dataset_v_1.npz\")\n",
    "\n",
    "dataset_container = DatasetContainer()\n",
    "dataset_container.load_from_dataset(resource_path / Path(\"images/uncalibrated/\") / file_to_calibrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibrated_dc = DatasetContainer()\n",
    "calibrated_dc.load_from_intrinsics(*dataset_container.get_camera_intrinscs())\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "index_params = dict(algorithm = 1, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "for rs_rgb, rs_depth, zv_rgb, zv_depth in dataset_container:\n",
    "    zv_kp, zv_des = sift.detectAndCompute(zv_rgb, None)\n",
    "    rs_kp, rs_des = sift.detectAndCompute(rs_rgb, None)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(zv_des, rs_des, k=2)\n",
    "\n",
    "    #-- Filter matches using the Lowe's ratio test\n",
    "    ratio_thresh = 0.7\n",
    "    good_matches = [m for m,n in matches if m.distance < ratio_thresh * n.distance]\n",
    "\n",
    "    #-- Draw matches\n",
    "    # img_matches = np.empty((max(zv_rgb.shape[0], rs_rgb.shape[0]), zv_rgb.shape[1] + zv_rgb.shape[1], 3), dtype=np.uint8)\n",
    "    # cv2.drawMatches(zv_rgb, zv_kp, rs_rgb, rs_kp, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    #-- Localize the object\n",
    "    obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    for i in range(len(good_matches)):\n",
    "        #-- Get the keypoints from the good matches\n",
    "        obj[i,0] = zv_kp[good_matches[i].queryIdx].pt[0]\n",
    "        obj[i,1] = zv_kp[good_matches[i].queryIdx].pt[1]\n",
    "        scene[i,0] = rs_kp[good_matches[i].trainIdx].pt[0]\n",
    "        scene[i,1] = rs_kp[good_matches[i].trainIdx].pt[1]\n",
    "    H, _ =  cv2.findHomography(obj, scene, cv2.RANSAC)\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "    # obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "    # obj_corners[0,0,0] = 0\n",
    "    # obj_corners[0,0,1] = 0\n",
    "    # obj_corners[1,0,0] = zv_rgb.shape[1]\n",
    "    # obj_corners[1,0,1] = 0\n",
    "    # obj_corners[2,0,0] = zv_rgb.shape[1]\n",
    "    # obj_corners[2,0,1] = zv_rgb.shape[0]\n",
    "    # obj_corners[3,0,0] = 0\n",
    "    # obj_corners[3,0,1] = zv_rgb.shape[0]\n",
    "    # scene_corners = cv2.perspectiveTransform(obj_corners, H)\n",
    "    # #-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "    # cv2.line(img_matches, (int(scene_corners[0,0,0] + zv_rgb.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "    #     (int(scene_corners[1,0,0] + zv_rgb.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[1,0,0] + zv_rgb.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "    #     (int(scene_corners[2,0,0] + zv_rgb.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[2,0,0] + zv_rgb.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "    #     (int(scene_corners[3,0,0] + zv_rgb.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[3,0,0] + zv_rgb.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "    #     (int(scene_corners[0,0,0] + zv_rgb.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "    # #-- Show detected matches\n",
    "\n",
    "    rs_rgb_warp = cv2.warpPerspective(rs_rgb, H_inv, (zv_rgb.shape[1], zv_rgb.shape[0]))\n",
    "    rs_depth_warp = cv2.warpPerspective(rs_depth, H_inv, (zv_rgb.shape[1], zv_rgb.shape[0]))\n",
    "\n",
    "    calibrated_dc.append(rs_rgb_warp, rs_depth_warp, zv_rgb, zv_depth)\n",
    "\n",
    "    # debug output\n",
    "    # plt.figure(2)\n",
    "    # plt.imshow(zv_rgb)\n",
    "\n",
    "    # plt.figure(3)\n",
    "    # plt.imshow(rs_rgb_warp)\n",
    "\n",
    "    # img_both = cv2.addWeighted(zv_rgb, 0.5, rs_rgb_warp, 0.5, 0)\n",
    "    # plt.figure(4)\n",
    "    # plt.imshow(img_both)\n",
    "\n",
    "calibrated_dc.save(resource_path / Path(\"images/calibrated\") / file_to_calibrate)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c772e1b5366734256a9870d5f099b9d4fdfd16c1a18810c4324b8e7acb8e99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
