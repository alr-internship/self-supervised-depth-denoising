{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate Cameras\n",
    "[https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html](https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dataset.dataset_interface import DatasetInterface\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_219703/1477419022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msearch_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrs_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_interface\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mzv_kp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_des\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzv_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrs_kp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_des\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Studium/KIT/Master/Semester_1/DL_Praktikum/self-supervised-depth-denoising/src/models/dataset/dataset_interface.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mrs_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rs_rgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrs_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rs_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resource_path = Path(\"../../resources\")\n",
    "uncal_path = resource_path / \"images/uncalibrated\"\n",
    "cal_path = resource_path / \"images/calibrated\"\n",
    "dir_to_calibrate = Path(\"c_dataset_d_1\")\n",
    "\n",
    "dataset_interface = DatasetInterface(uncal_path / dir_to_calibrate)\n",
    "\n",
    "calibrated_dc = DatasetInterface(cal_path / dir_to_calibrate)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "index_params = dict(algorithm = 1, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "for rs_rgb, rs_depth, zv_rgb, zv_depth in dataset_interface:\n",
    "    zv_kp, zv_des = sift.detectAndCompute(zv_rgb, None)\n",
    "    rs_kp, rs_des = sift.detectAndCompute(rs_rgb, None)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(zv_des, rs_des, k=2)\n",
    "\n",
    "    #-- Filter matches using the Lowe's ratio test\n",
    "    ratio_thresh = 0.7\n",
    "    good_matches = [m for m,n in matches if m.distance < ratio_thresh * n.distance]\n",
    "\n",
    "    #-- Draw matches\n",
    "    # img_matches = np.empty((max(zv_rgb.shape[0], rs_rgb.shape[0]), zv_rgb.shape[1] + zv_rgb.shape[1], 3), dtype=np.uint8)\n",
    "    # cv2.drawMatches(zv_rgb, zv_kp, rs_rgb, rs_kp, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    #-- Localize the object\n",
    "    obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    for i in range(len(good_matches)):\n",
    "        #-- Get the keypoints from the good matches\n",
    "        obj[i,0] = zv_kp[good_matches[i].queryIdx].pt[0]\n",
    "        obj[i,1] = zv_kp[good_matches[i].queryIdx].pt[1]\n",
    "        scene[i,0] = rs_kp[good_matches[i].trainIdx].pt[0]\n",
    "        scene[i,1] = rs_kp[good_matches[i].trainIdx].pt[1]\n",
    "    H, _ =  cv2.findHomography(obj, scene, cv2.RANSAC)\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "    # obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "    # obj_corners[0,0,0] = 0\n",
    "    # obj_corners[0,0,1] = 0\n",
    "    # obj_corners[1,0,0] = zv_rgb.shape[1]\n",
    "    # obj_corners[1,0,1] = 0\n",
    "    # obj_corners[2,0,0] = zv_rgb.shape[1]\n",
    "    # obj_corners[2,0,1] = zv_rgb.shape[0]\n",
    "    # obj_corners[3,0,0] = 0\n",
    "    # obj_corners[3,0,1] = zv_rgb.shape[0]\n",
    "    # scene_corners = cv2.perspectiveTransform(obj_corners, H)\n",
    "    # #-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "    # cv2.line(img_matches, (int(scene_corners[0,0,0] + zv_rgb.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "    #     (int(scene_corners[1,0,0] + zv_rgb.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[1,0,0] + zv_rgb.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "    #     (int(scene_corners[2,0,0] + zv_rgb.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[2,0,0] + zv_rgb.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "    #     (int(scene_corners[3,0,0] + zv_rgb.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "    # cv2.line(img_matches, (int(scene_corners[3,0,0] + zv_rgb.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "    #     (int(scene_corners[0,0,0] + zv_rgb.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "    # #-- Show detected matches\n",
    "\n",
    "    rs_rgb_warp = cv2.warpPerspective(rs_rgb, H_inv, (zv_rgb.shape[1], zv_rgb.shape[0]))\n",
    "    rs_depth_warp = cv2.warpPerspective(rs_depth, H_inv, (zv_rgb.shape[1], zv_rgb.shape[0]))\n",
    "\n",
    "    calibrated_dc.append_and_save(rs_rgb_warp, rs_depth_warp, zv_rgb, zv_depth)\n",
    "\n",
    "    # debug output\n",
    "    # plt.figure(2)\n",
    "    # plt.imshow(zv_rgb)\n",
    "\n",
    "    # plt.figure(3)\n",
    "    # plt.imshow(rs_rgb_warp)\n",
    "\n",
    "    # img_both = cv2.addWeighted(zv_rgb, 0.5, rs_rgb_warp, 0.5, 0)\n",
    "    # plt.figure(4)\n",
    "    # plt.imshow(img_both)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c772e1b5366734256a9870d5f099b9d4fdfd16c1a18810c4324b8e7acb8e99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
