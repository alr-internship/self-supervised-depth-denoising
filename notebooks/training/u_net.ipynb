{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [https://github.com/milesial/Pytorch-UNet](https://github.com/milesial/Pytorch-UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required models\n",
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.networks.UNet import UNet\n",
    "from models.utils.data_loading import BasicDataset\n",
    "from models.utils.dice_score import dice_loss, dice_coeff, multiclass_dice_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  epochs = 5                  # Number of epochs\n",
    "  batch_size = 1              # Batch size\n",
    "  learning_rate = 0.00001     # Learning rate\n",
    "  load = None                 # Load model from a .pth file (path)\n",
    "  scale = 0.5                 # Downscaling factor of the images\n",
    "  validation = 10.0           # Percent of the data that is used as validation (0-100)\n",
    "  amp = False                 # Use mixed precision\n",
    "  wandb = True                # toggle the usage of wandb for logging purposes \n",
    "  save = False                # save trained model\n",
    "  dir_img = Path('../resources/images/calibrated/realsense/depth/')\n",
    "  dir_label = Path('../resources/images/calibrated/zivid/depth/')\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net: UNet, dataloader: DataLoader, device: torch.device):\n",
    "    net.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    loss = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "        image, mask_true = batch['image'], batch['mask']\n",
    "        # move images and labels to correct device and type\n",
    "        image = image.to(device=device, dtype=torch.float32)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.float32)            # NxWxH\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # predict the mask\n",
    "            mask_pred = net(image)\n",
    "            loss += torch.abs(mask_pred - mask_true).sum()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return loss \n",
    "    return loss / num_val_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net: UNet,\n",
    "              device: torch.device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 0.001,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    dataset = BasicDataset(args.dir_img, args.dir_label, img_scale)\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    # TODO: check if generator needed!\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    if args.wandb:\n",
    "        experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "        experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                    val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "                                    amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "        ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.L1Loss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "\n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks)\n",
    "                    \"\"\"\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "                    \"\"\"\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                \"\"\"\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                \"\"\"\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (10 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        val_score = evaluate(net, val_loader, device)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "\n",
    "                        if args.wandb:\n",
    "                            histograms = {}\n",
    "                            for tag, value in net.named_parameters():\n",
    "                                tag = tag.replace('/', '.')\n",
    "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                            experiment.log({\n",
    "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                                'validation Dice': val_score,\n",
    "                                'images': wandb.Image(images[0].cpu()),\n",
    "                                'masks': {\n",
    "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                    'pred': wandb.Image(torch.softmax(masks_pred, dim=1).argmax(dim=1)[0].float().cpu()),\n",
    "                                },\n",
    "                                'step': global_step,\n",
    "                                'epoch': epoch,\n",
    "                                **histograms\n",
    "                            })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch + 1)))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n",
      "INFO: Network:\n",
      "\t1 input channels\n",
      "\t1 output channels (classes)\n",
      "\tBilinear upscaling\n",
      "INFO: Creating dataset with 33 examples\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-162529\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/claudiusk/.conda/envs/depth-denoising_training/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/anony-mouse-162529/U-Net/runs/1ydz9acq?apiKey=9d5811f822fff0143428d2e81a37df5c4b3ca7ec\" target=\"_blank\">faithful-field-5</a></strong> to <a href=\"https://wandb.ai/anony-mouse-162529/U-Net?apiKey=9d5811f822fff0143428d2e81a37df5c4b3ca7ec\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   30\n",
      "        Validation size: 3\n",
      "        Checkpoints:     True\n",
      "        Device:          cpu\n",
      "        Images scaling:  0.5\n",
      "        Mixed Precision: False\n",
      "        \n",
      "Epoch 1/5:   0%|          | 0/30 [00:00<?, ?img/s]/home/claudiusk/.conda/envs/depth-denoising_training/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Epoch 1/5:  10%|█         | 3/30 [00:22<03:25,  7.62s/img, loss (batch)=0.331]INFO: Validation Dice score: 129834.25\n",
      "Epoch 1/5:  20%|██        | 6/30 [00:52<03:23,  8.50s/img, loss (batch)=0.222]INFO: Validation Dice score: 113372.0546875\n",
      "Epoch 1/5:  30%|███       | 9/30 [01:20<02:59,  8.55s/img, loss (batch)=0.237]INFO: Validation Dice score: 101385.0390625\n",
      "Epoch 1/5:  40%|████      | 12/30 [01:48<02:35,  8.62s/img, loss (batch)=0.186]INFO: Validation Dice score: 95248.3046875\n",
      "Epoch 1/5:  50%|█████     | 15/30 [02:17<02:13,  8.87s/img, loss (batch)=0.274]INFO: Validation Dice score: 88621.4375\n",
      "Epoch 1/5:  60%|██████    | 18/30 [02:46<01:44,  8.70s/img, loss (batch)=0.162]INFO: Validation Dice score: 87432.2890625\n",
      "Epoch 1/5:  70%|███████   | 21/30 [03:12<01:14,  8.23s/img, loss (batch)=0.151]INFO: Validation Dice score: 87469.46875\n",
      "Epoch 1/5:  80%|████████  | 24/30 [03:38<00:48,  8.16s/img, loss (batch)=0.269]INFO: Validation Dice score: 90428.5859375\n",
      "Epoch 1/5:  90%|█████████ | 27/30 [04:04<00:24,  8.03s/img, loss (batch)=0.139]INFO: Validation Dice score: 92759.8046875\n",
      "Epoch 1/5: 100%|██████████| 30/30 [04:31<00:00,  8.07s/img, loss (batch)=0.257]INFO: Validation Dice score: 98793.8046875\n",
      "Epoch 1/5: 100%|██████████| 30/30 [04:37<00:00,  9.26s/img, loss (batch)=0.257]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dir_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48358/3231391803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     train_net(net=net,\n\u001b[0m\u001b[1;32m     22\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48358/2529419611.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, epochs, batch_size, learning_rate, val_percent, save_checkpoint, img_scale, amp)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_checkpoint\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'checkpoint_epoch{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Checkpoint {epoch + 1} saved!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "net = UNet(n_channels=1, n_classes=1, bilinear=True)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "              f'\\t{net.n_channels} input channels\\n'\n",
    "              f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "              f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if args.load:\n",
    "    net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "    logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "net.to(device=device)\n",
    "try:\n",
    "    train_net(net=net,\n",
    "              epochs=args.epochs,\n",
    "              batch_size=args.batch_size,\n",
    "              learning_rate=args.learning_rate,\n",
    "              device=device,\n",
    "              img_scale=args.scale,\n",
    "              save_checkpoint=args.save,\n",
    "              val_percent=args.validation / 100,\n",
    "              amp=args.amp)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a16bc2ce7b7f1639c4a57155c0fb5a1be6acb415dada3521f659853ec55ce1a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('depth-denoising': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
