{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [https://github.com/milesial/Pytorch-UNet](https://github.com/milesial/Pytorch-UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required models\n",
    "import sys\n",
    "sys.path.append(\"../../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.networks.UNet import UNet\n",
    "from models.dataset.data_loading import BasicDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  epochs = 5                  # Number of epochs\n",
    "  batch_size = 1              # Batch size\n",
    "  learning_rate = 0.00001     # Learning rate\n",
    "  load = None                 # Load model from a .pth file (path)\n",
    "  scale = 0.5                 # Downscaling factor of the images\n",
    "  validation = 10.0           # Percent of the data that is used as validation (0-100)\n",
    "  amp = False                 # Use mixed precision\n",
    "  wandb = True                # toggle the usage of wandb for logging purposes \n",
    "  save = False                # save trained model\n",
    "  dataset_path = Path(\"../../resources/images/calibrated/pseudo_calibrated_images.npz\")\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net: UNet, dataloader: DataLoader, device: torch.device):\n",
    "    net.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    loss = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "        image, mask_true = batch['image'], batch['mask']\n",
    "        # move images and labels to correct device and type\n",
    "        image = image.to(device=device, dtype=torch.float32)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.float32)            # NxWxH\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # predict the mask\n",
    "            mask_pred = net(image)\n",
    "            loss += torch.abs(mask_pred - mask_true).sum()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return loss \n",
    "\n",
    "    return loss / num_val_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net: UNet,\n",
    "              device: torch.device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 0.001,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    dataset = BasicDataset(args.dataset_path, img_scale)\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    # TODO: check if generator needed!\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    if args.wandb:\n",
    "        experiment = wandb.init(project='U-Net', resume='allow', entity=\"depth-denoising\")\n",
    "        experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                    val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "                                    amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "        ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.L1Loss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "\n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks)\n",
    "                    \"\"\"\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "                    \"\"\"\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if args.wandb:\n",
    "                    experiment.log({\n",
    "                        'train loss': loss.item(),\n",
    "                        'step': global_step,\n",
    "                        'epoch': epoch\n",
    "                    })\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (10 * batch_size))\n",
    "                if division_step > 0 and global_step % division_step == 0:\n",
    "                    val_loss = evaluate(net, val_loader, device)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    logging.info('Validation Loss: {}'.format(val_loss))\n",
    "\n",
    "                    if args.wandb:\n",
    "                        histograms = {}\n",
    "                        for tag, value in net.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        experiment.log({\n",
    "                            'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                            'validation loss': val_loss,\n",
    "                            'images': wandb.Image(images[0].cpu()),\n",
    "                            'masks': {\n",
    "                                'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                'pred': wandb.Image(masks_pred[0].float().cpu()),\n",
    "                            },\n",
    "                            'step': global_step,\n",
    "                            'epoch': epoch,\n",
    "                            **histograms\n",
    "                        })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch + 1)))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n",
      "INFO: Network:\n",
      "\t1 input channels\n",
      "\t1 output channels (classes)\n",
      "\tBilinear upscaling\n",
      "INFO: Creating dataset with 24 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:21cs889l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 148555... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>learning rate</td><td>████████▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train loss</td><td>█▄▇▅▃▂▂▂▂▁▃▁▂▁▃▁▁▁▂▁▂▂▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▂▁▃</td></tr><tr><td>validation loss</td><td>▄▃▅▇▇▇▇▄▁▄▆██▆▄▄▃▃▃▃▄▆▅▅▅▅▃▃▃▂▃▆▄▆▅▄▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>step</td><td>110</td></tr><tr><td>train loss</td><td>0.11829</td></tr><tr><td>validation loss</td><td>11283.55078</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 165 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vivid-silence-5</strong>: <a href=\"https://wandb.ai/depth-denoising/U-Net/runs/21cs889l\" target=\"_blank\">https://wandb.ai/depth-denoising/U-Net/runs/21cs889l</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211127_160426-21cs889l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:21cs889l). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/depth-denoising/U-Net/runs/3jihxd30\" target=\"_blank\">toasty-cosmos-6</a></strong> to <a href=\"https://wandb.ai/depth-denoising/U-Net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   22\n",
      "        Validation size: 2\n",
      "        Checkpoints:     False\n",
      "        Device:          cpu\n",
      "        Images scaling:  0.5\n",
      "        Mixed Precision: False\n",
      "        \n",
      "Epoch 1/5:   0%|          | 0/22 [00:00<?, ?img/s]/home/claudiusk/.conda/envs/depth-denoising_training/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Epoch 1/5:   9%|▉         | 2/22 [00:15<02:32,  7.62s/img, loss (batch)=0.21] INFO: Validation Loss: 25530.2578125\n",
      "Epoch 1/5:  18%|█▊        | 4/22 [00:36<02:46,  9.25s/img, loss (batch)=0.192]INFO: Validation Loss: 24151.892578125\n",
      "Epoch 1/5:  27%|██▋       | 6/22 [00:55<02:29,  9.37s/img, loss (batch)=0.161] INFO: Validation Loss: 22475.25390625\n",
      "Epoch 1/5:  36%|███▋      | 8/22 [01:15<02:10,  9.33s/img, loss (batch)=0.0969]INFO: Validation Loss: 17499.0234375\n",
      "Epoch 1/5:  45%|████▌     | 10/22 [01:35<01:54,  9.55s/img, loss (batch)=0.0879]INFO: Validation Loss: 14605.671875\n",
      "Epoch 1/5:  55%|█████▍    | 12/22 [01:54<01:32,  9.29s/img, loss (batch)=0.102]INFO: Validation Loss: 14108.01171875\n",
      "Epoch 1/5:  64%|██████▎   | 14/22 [02:15<01:15,  9.46s/img, loss (batch)=0.0708]INFO: Validation Loss: 13857.7021484375\n",
      "Epoch 1/5:  73%|███████▎  | 16/22 [02:35<00:57,  9.54s/img, loss (batch)=0.0529]INFO: Validation Loss: 13957.462890625\n",
      "Epoch 1/5:  82%|████████▏ | 18/22 [02:54<00:36,  9.18s/img, loss (batch)=0.0655]INFO: Validation Loss: 14917.2138671875\n",
      "Epoch 1/5:  91%|█████████ | 20/22 [03:13<00:18,  9.21s/img, loss (batch)=0.0644]INFO: Validation Loss: 15241.103515625\n",
      "Epoch 1/5: 100%|██████████| 22/22 [03:31<00:00,  9.01s/img, loss (batch)=0.0526]INFO: Validation Loss: 18934.72265625\n",
      "Epoch 1/5: 100%|██████████| 22/22 [03:36<00:00,  9.85s/img, loss (batch)=0.0526]\n",
      "Epoch 2/5:   9%|▉         | 2/22 [00:14<02:21,  7.09s/img, loss (batch)=0.0641]INFO: Validation Loss: 23493.65234375\n",
      "Epoch 2/5:  18%|█▊        | 4/22 [00:33<02:30,  8.37s/img, loss (batch)=0.115] INFO: Validation Loss: 28081.146484375\n",
      "Epoch 2/5:  27%|██▋       | 6/22 [00:54<02:29,  9.32s/img, loss (batch)=0.0646]INFO: Validation Loss: 30856.671875\n",
      "Epoch 2/5:  36%|███▋      | 8/22 [01:16<02:19,  9.97s/img, loss (batch)=0.0617]INFO: Validation Loss: 34374.7265625\n",
      "Epoch 2/5:  45%|████▌     | 10/22 [01:36<01:55,  9.66s/img, loss (batch)=0.063] INFO: Validation Loss: 38360.71484375\n",
      "Epoch 2/5:  55%|█████▍    | 12/22 [01:55<01:34,  9.47s/img, loss (batch)=0.0537]INFO: Validation Loss: 41146.23828125\n",
      "Epoch 2/5:  64%|██████▎   | 14/22 [02:14<01:14,  9.27s/img, loss (batch)=0.103]INFO: Validation Loss: 35347.859375\n",
      "Epoch 2/5:  73%|███████▎  | 16/22 [02:34<00:56,  9.34s/img, loss (batch)=0.0548]INFO: Validation Loss: 34494.765625\n",
      "Epoch 2/5:  82%|████████▏ | 18/22 [02:55<00:38,  9.71s/img, loss (batch)=0.0511]INFO: Validation Loss: 33840.53125\n",
      "Epoch 2/5:  91%|█████████ | 20/22 [03:16<00:19,  9.76s/img, loss (batch)=0.0617]INFO: Validation Loss: 31770.078125\n",
      "Epoch 2/5: 100%|██████████| 22/22 [03:37<00:00, 10.15s/img, loss (batch)=0.0668]INFO: Validation Loss: 26346.234375\n",
      "Epoch 2/5: 100%|██████████| 22/22 [03:43<00:00, 10.16s/img, loss (batch)=0.0668]\n",
      "Epoch 3/5:   9%|▉         | 2/22 [00:15<02:36,  7.80s/img, loss (batch)=0.0623]INFO: Validation Loss: 24291.6484375\n",
      "Epoch 3/5:  18%|█▊        | 4/22 [00:35<02:41,  8.98s/img, loss (batch)=0.0529]INFO: Validation Loss: 25919.4375\n",
      "Epoch 3/5:  27%|██▋       | 6/22 [00:57<02:34,  9.66s/img, loss (batch)=0.0634]INFO: Validation Loss: 27010.72265625\n",
      "Epoch 3/5:  36%|███▋      | 8/22 [01:18<02:20, 10.03s/img, loss (batch)=0.0997]INFO: Validation Loss: 24557.35546875\n",
      "Epoch 3/5:  45%|████▌     | 10/22 [01:40<02:00, 10.06s/img, loss (batch)=0.102] INFO: Validation Loss: 13291.5224609375\n",
      "Epoch 3/5:  55%|█████▍    | 12/22 [02:00<01:38,  9.84s/img, loss (batch)=0.0763]INFO: Validation Loss: 15299.3134765625\n",
      "Epoch 3/5:  64%|██████▎   | 14/22 [02:21<01:18,  9.85s/img, loss (batch)=0.0605]INFO: Validation Loss: 18744.2734375\n",
      "Epoch 3/5:  73%|███████▎  | 16/22 [02:42<01:00, 10.04s/img, loss (batch)=0.112] INFO: Validation Loss: 10962.197265625\n",
      "Epoch 3/5:  82%|████████▏ | 18/22 [03:01<00:37,  9.48s/img, loss (batch)=0.0605]INFO: Validation Loss: 11896.451171875\n",
      "Epoch 3/5:  91%|█████████ | 20/22 [03:19<00:18,  9.05s/img, loss (batch)=0.0617]INFO: Validation Loss: 12493.2080078125\n",
      "Epoch 3/5: 100%|██████████| 22/22 [03:40<00:00,  9.42s/img, loss (batch)=0.0607]INFO: Validation Loss: 15386.15234375\n",
      "Epoch 3/5: 100%|██████████| 22/22 [03:45<00:00, 10.26s/img, loss (batch)=0.0607]\n",
      "Epoch 4/5:   9%|▉         | 2/22 [00:16<02:41,  8.05s/img, loss (batch)=0.0614]INFO: Validation Loss: 15971.86328125\n",
      "Epoch 4/5:  18%|█▊        | 4/22 [00:36<02:41,  8.98s/img, loss (batch)=0.052] INFO: Validation Loss: 19056.625\n",
      "Epoch 4/5:  27%|██▋       | 6/22 [00:56<02:28,  9.28s/img, loss (batch)=0.0596]INFO: Validation Loss: 16381.34375\n",
      "Epoch 4/5:  36%|███▋      | 8/22 [01:16<02:13,  9.57s/img, loss (batch)=0.0515]INFO: Validation Loss: 15234.537109375\n",
      "Epoch 4/5:  45%|████▌     | 10/22 [01:36<01:54,  9.53s/img, loss (batch)=0.0526]INFO: Validation Loss: 18182.8359375\n",
      "Epoch 4/5:  55%|█████▍    | 12/22 [01:56<01:34,  9.44s/img, loss (batch)=0.06]  INFO: Validation Loss: 19290.47265625\n",
      "Epoch 4/5:  64%|██████▎   | 14/22 [02:15<01:14,  9.25s/img, loss (batch)=0.0746]INFO: Validation Loss: 10447.67578125\n",
      "Epoch 4/5:  73%|███████▎  | 16/22 [02:34<00:54,  9.15s/img, loss (batch)=0.101] INFO: Validation Loss: 10064.3857421875\n",
      "Epoch 4/5:  82%|████████▏ | 18/22 [02:54<00:37,  9.39s/img, loss (batch)=0.0987]INFO: Validation Loss: 9299.2802734375\n",
      "Epoch 4/5:  91%|█████████ | 20/22 [03:13<00:18,  9.29s/img, loss (batch)=0.0596]INFO: Validation Loss: 10709.259765625\n",
      "Epoch 4/5: 100%|██████████| 22/22 [03:34<00:00,  9.67s/img, loss (batch)=0.0588]INFO: Validation Loss: 10465.1953125\n",
      "Epoch 4/5: 100%|██████████| 22/22 [03:39<00:00,  9.98s/img, loss (batch)=0.0588]\n",
      "Epoch 5/5:   9%|▉         | 2/22 [00:14<02:25,  7.26s/img, loss (batch)=0.0515]INFO: Validation Loss: 17389.376953125\n",
      "Epoch 5/5:  18%|█▊        | 4/22 [00:34<02:40,  8.91s/img, loss (batch)=0.0518]INFO: Validation Loss: 18868.12890625\n",
      "Epoch 5/5:  27%|██▋       | 6/22 [00:55<02:32,  9.51s/img, loss (batch)=0.0592]INFO: Validation Loss: 18398.984375\n",
      "Epoch 5/5:  36%|███▋      | 8/22 [01:14<02:09,  9.26s/img, loss (batch)=0.0619]INFO: Validation Loss: 20197.09765625\n",
      "Epoch 5/5:  45%|████▌     | 10/22 [01:33<01:49,  9.09s/img, loss (batch)=0.0586]INFO: Validation Loss: 14995.96484375\n",
      "Epoch 5/5:  55%|█████▍    | 12/22 [01:52<01:30,  9.05s/img, loss (batch)=0.0592]INFO: Validation Loss: 15223.83203125\n",
      "Epoch 5/5:  64%|██████▎   | 14/22 [02:10<01:11,  8.94s/img, loss (batch)=0.048] INFO: Validation Loss: 18503.693359375\n",
      "Epoch 5/5:  73%|███████▎  | 16/22 [02:29<00:53,  8.86s/img, loss (batch)=0.0581]INFO: Validation Loss: 18079.591796875\n",
      "Epoch 5/5:  82%|████████▏ | 18/22 [02:48<00:35,  8.98s/img, loss (batch)=0.0525]INFO: Validation Loss: 17669.98828125\n",
      "Epoch 5/5:  91%|█████████ | 20/22 [03:06<00:17,  8.97s/img, loss (batch)=0.151] INFO: Validation Loss: 22730.70703125\n",
      "Epoch 5/5: 100%|██████████| 22/22 [03:26<00:00,  9.14s/img, loss (batch)=0.0487]INFO: Validation Loss: 17648.25390625\n",
      "Epoch 5/5: 100%|██████████| 22/22 [03:31<00:00,  9.63s/img, loss (batch)=0.0487]\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "net = UNet(n_channels=1, n_classes=1, bilinear=True)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "              f'\\t{net.n_channels} input channels\\n'\n",
    "              f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "              f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if args.load:\n",
    "    net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "    logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "net.to(device=device)\n",
    "try:\n",
    "    train_net(net=net,\n",
    "              epochs=args.epochs,\n",
    "              batch_size=args.batch_size,\n",
    "              learning_rate=args.learning_rate,\n",
    "              device=device,\n",
    "              img_scale=args.scale,\n",
    "              save_checkpoint=args.save,\n",
    "              val_percent=args.validation / 100,\n",
    "              amp=args.amp)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a16bc2ce7b7f1639c4a57155c0fb5a1be6acb415dada3521f659853ec55ce1a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('depth-denoising': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
