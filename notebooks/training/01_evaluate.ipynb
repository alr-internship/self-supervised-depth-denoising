{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-01-31 15:40:13,500 - 2333500916 - Loading model ../../resources/networks/e500.pth\n",
      "INFO - 2022-01-31 15:40:13,500 - 2333500916 - Using device cpu\n",
      "INFO - 2022-01-31 15:40:13,531 - 2333500916 - Model loaded!\n",
      "INFO - 2022-01-31 15:40:13,629 - 2333500916 - \n",
      "Predicting image ../../resources/images/old/c_dataset_h_1/1642786298.3779597.npz ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1200,1920,3) (1080,1920,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44660/2333500916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mcrop_region_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1600\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mrs_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_rgb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcrop_region_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mzv_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzv_rgb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcrop_region_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mrs_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_region_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mzv_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_region_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1200,1920,3) (1080,1920,1) "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset.data_loading import BasicDataset\n",
    "from dataset.dataset_interface import DatasetInterface\n",
    "from networks.UNet.unet_model import UNet\n",
    "from calibration.calib_in_pcd import imgs_to_pcd, rs_ci\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "\n",
    "from utils.visualization_utils import visualize_depth, to_rgb\n",
    "\n",
    "resource_path = Path(\"../../resources\")\n",
    "\n",
    "class Args:\n",
    "    model = resource_path / \"networks/e500.pth\"\n",
    "    input = resource_path / \"images/calibrated/3d_aligned/dataset_4\"\n",
    "    scale = 0.5\n",
    "\n",
    "args = Args()\n",
    "dataset = DatasetInterface(Path(args.input))\n",
    "\n",
    "net = UNet(n_input_channels=5, n_output_channels=1)\n",
    "net = nn.DataParallel(net)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Loading model {args.model}')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(args.model, map_location=device))\n",
    "\n",
    "logging.info('Model loaded!')\n",
    "\n",
    "idx = np.random.randint(len(dataset), size=1).item()\n",
    "files = dataset[idx]\n",
    "\n",
    "logging.info(f'\\nPredicting image {dataset.data_file_paths[idx]} ...')\n",
    "\n",
    "net.eval()\n",
    "rs_rgb, rs_depth, zv_rgb, zv_depth = files\n",
    "crop_region_mask = np.zeros((rs_rgb.shape[:2]), dtype=np.uint8)\n",
    "crop_region_mask[:, 500:1600] = 1\n",
    "rs_rgb = rs_rgb * crop_region_mask[..., None]\n",
    "zv_rgb = zv_rgb * crop_region_mask[..., None]\n",
    "rs_depth = np.where(crop_region_mask, rs_depth, np.nan)\n",
    "zv_depth = np.where(crop_region_mask, zv_depth, np.nan)\n",
    "\n",
    "set = BasicDataset.preprocess_set(rs_rgb, rs_depth, zv_depth, args.scale, True)\n",
    "img = set['image']\n",
    "nan_mask = set['nan-mask']\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_depths = net(img)\n",
    "    pred_depth = (pred_depths * nan_mask)[0, 0].float().cpu().detach().numpy()\n",
    "\n",
    "input_rgb = BasicDataset.resize(rs_rgb, args.scale)\n",
    "output_rgb = BasicDataset.resize(zv_rgb, args.scale)\n",
    "input_depth = BasicDataset.resize(rs_depth, args.scale)\n",
    "real_depth = BasicDataset.resize(zv_depth, args.scale)\n",
    "depths = np.concatenate((input_depth, pred_depth, real_depth), axis=1)\n",
    "\n",
    "real_depth = np.nan_to_num(real_depth)\n",
    "input_depth = np.nan_to_num(input_depth)\n",
    "\n",
    "print(f\"Means: Input {np.nanmean(input_depth)} Label {np.nanmean(real_depth)} Predicted {np.mean(pred_depth)}\")\n",
    "\n",
    "pred_pcd = imgs_to_pcd(input_rgb, pred_depth, rs_ci)\n",
    "input_pcd = imgs_to_pcd(input_rgb, input_depth, rs_ci)\n",
    "output_pcd = imgs_to_pcd(output_rgb, real_depth, rs_ci)\n",
    "o3d.visualization.draw_geometries([input_pcd])\n",
    "o3d.visualization.draw_geometries([input_pcd, output_pcd])\n",
    "\n",
    "_, axarr = plt.subplots(1, 4, figsize=(30, 10))\n",
    "axarr[0].title.set_text(\"Input\")\n",
    "axarr[0].imshow(visualize_depth(input_depth))\n",
    "axarr[1].title.set_text(\"Label\")\n",
    "axarr[1].imshow(visualize_depth(real_depth))\n",
    "axarr[2].title.set_text(\"Prediction\")\n",
    "axarr[2].imshow(visualize_depth(pred_depth))\n",
    "axarr[3].imshow(to_rgb(rs_rgb))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01a16f79f532d1c1341341ac795aec2cbe29f2735db7183bbfd348431b323282"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('depth-denoising_training': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
