{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset.data_loading import BasicDataset\n",
    "from dataset.dataset_interface import DatasetInterface\n",
    "from networks.UNet.unet_model import UNet\n",
    "import open3d as o3d\n",
    "from utils.visualization_utils import visualize_depth, to_rgb\n",
    "from utils.transformation_utils import imgs_to_pcd, rs_ci, unnormalize_depth\n",
    "import yaml\n",
    "\n",
    "root_path = Path(\"../\")\n",
    "\n",
    "class Args:\n",
    "    trainer_id = \"1646537403.2871037\"\n",
    "    model_dir = root_path / f\"local_resources/hp_models/{trainer_id}/M_total\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# following command copies the \n",
    "src_path = f\"ng3916@bwunicluster.scc.kit.edu:~/self-supervised-depth-denoising/{args.model_dir.relative_to(root_path).parent}\"\n",
    "dest_path = args.model_dir.parent.parent\n",
    "if not (Path(dest_path) / args.trainer_id).exists():\n",
    "    !scp -r $src_path $dest_path\n",
    "\n",
    "config_path = args.model_dir.parent / \"config.yml\"\n",
    "model = natsorted(args.model_dir.glob(\"*.pth\"), key=lambda f: f.stem.split('e')[1])[-1]\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "network_config = config['network_config']\n",
    "trainer_config = config['basic_trainer']\n",
    "dataset_config_yaml = config['dataset_config']\n",
    "dataset_config = BasicDataset.Config.from_config(dataset_config_yaml)\n",
    "network_config = {\n",
    "    'name': 'M_total',\n",
    "    'n_input_channels': dataset_config.num_in_channels(),\n",
    "    'n_output_channels': 1,\n",
    "    **network_config\n",
    "}\n",
    "unet_config = UNet.Config.from_config(network_config)\n",
    "\n",
    "path = root_path / Path(trainer_config['train_path']).parent / \"test_dataset.json\"\n",
    "logging.info(f\"using path {path}\")\n",
    "files = DatasetInterface.get_files_by_path(path)\n",
    "net = UNet(unet_config)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "logging.info(f'Loading model {model}')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(model, map_location=device))\n",
    "# fixes wrongly saved weights from data parallel\n",
    "# tmp_net = nn.DataParallel(net)\n",
    "# tmp_net.load_state_dict(torch.load(model, map_location=device))\n",
    "# model.unlink()\n",
    "# torch.save(tmp_net.module.state_dict(), model)\n",
    "# net.load_state_dict(torch.load(model, Map_location=device))\n",
    "net.eval()\n",
    "\n",
    "logging.info('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(files), size=1).item()\n",
    "idx = 28\n",
    "rs_rgb, rs_depth, zv_rgb, zv_depth, mask = DatasetInterface.load(files[idx])\n",
    "\n",
    "logging.info(f'\\nPredicting image {files[idx]} {idx}...')\n",
    "\n",
    "rs_min = np.nanmin(rs_depth)\n",
    "rs_max = np.nanmax(rs_depth)\n",
    "\n",
    "set = BasicDataset.preprocess_set(rs_rgb, rs_depth, mask, zv_depth, dataset_config)\n",
    "img = set['image'].unsqueeze(0)\n",
    "img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad() and torch.cuda.amp.autocast(enabled=network_config['amp']):\n",
    "    pred_depths = net(img)\n",
    "    pred_depth = pred_depths.squeeze().float().cpu().detach().numpy()\n",
    "\n",
    "pred_depth = BasicDataset.postprocess_set(set, pred_depth, dataset_config)\n",
    "\n",
    "# apply mask to input images\n",
    "rs_depth = np.where(mask, rs_depth, np.nan)\n",
    "zv_depth = np.where(mask, zv_depth, np.nan)\n",
    "\n",
    "depth_difference = np.abs(rs_depth - zv_depth)\n",
    "ot_depth_difference = np.abs(pred_depth - zv_depth)\n",
    "max_depth_difference = np.nanmax(depth_difference)\n",
    "logging.info(f\"Mean depths: Input {np.nanmean(rs_depth)} Label {np.nanmean(zv_depth)} Predicted {np.nanmean(pred_depth)}\")\n",
    "logging.info(f\"Max depth difference : IT {max_depth_difference}\")\n",
    "logging.info(f\"Distance IT {np.nansum(np.abs(depth_difference))/ np.sum(mask)}\")\n",
    "logging.info(f\"Distance OT {np.nansum(np.abs(zv_depth - pred_depth)) / np.sum(mask)}\")\n",
    "\n",
    "pred_pcd = imgs_to_pcd(rs_rgb, pred_depth, rs_ci)\n",
    "input_depth_difference_pcd = imgs_to_pcd(((depth_difference / max_depth_difference) * 255).astype(np.uint8), rs_depth, rs_ci)\n",
    "ot_depth_difference_pcd = imgs_to_pcd(((ot_depth_difference / np.nanmax(ot_depth_difference)) * 255).astype(np.uint8), rs_depth, rs_ci)\n",
    "input_pcd = imgs_to_pcd(rs_rgb, rs_depth.astype(np.float32), rs_ci)\n",
    "output_pcd = imgs_to_pcd(zv_rgb, zv_depth, rs_ci)\n",
    "\n",
    "o3d.visualization.draw_geometries([input_pcd])\n",
    "o3d.visualization.draw_geometries([output_pcd])\n",
    "# o3d.visualization.draw_geometries([input_depth_difference_pcd])\n",
    "# o3d.visualization.draw_geometries([ot_depth_difference_pcd])\n",
    "o3d.visualization.draw_geometries([pred_pcd])\n",
    "o3d.visualization.draw_geometries([input_pcd, output_pcd])\n",
    "o3d.visualization.draw_geometries([input_pcd, pred_pcd])\n",
    "o3d.visualization.draw_geometries([pred_pcd, output_pcd])\n",
    "\n",
    "_, axarr = plt.subplots(1, 3, figsize=(30, 10))\n",
    "# axarr[0].title.set_text(\"Input\")\n",
    "axarr[0].axis('off')\n",
    "axarr[0].imshow(visualize_depth(rs_depth))\n",
    "# axarr[1].title.set_text(\"Label\")\n",
    "axarr[1].axis('off')\n",
    "axarr[1].imshow(visualize_depth(zv_depth))\n",
    "# axarr[2].title.set_text(\"Prediction\")\n",
    "axarr[2].axis('off')\n",
    "axarr[2].imshow(visualize_depth(pred_depth))\n",
    "# axarr[3].imshow(mask)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"eval.png\", bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8ac6b8f7847e7c462e3f7405388b5cb94faacccf5869628990e3a1abaf917f9"
  },
  "kernelspec": {
   "display_name": "Python training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
