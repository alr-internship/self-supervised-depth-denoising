{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-02-23 16:40:52,969 - 670424406 - Loading model ../resources_local/models/1645624568.8774056/M_total/e3.pth\n",
      "INFO - 2022-02-23 16:40:52,971 - 670424406 - Using device cpu\n",
      "INFO - 2022-02-23 16:40:53,026 - 670424406 - Model loaded!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset.data_loading import BasicDataset\n",
    "from dataset.dataset_interface import DatasetInterface\n",
    "from networks.UNet.unet_model import UNet\n",
    "import open3d as o3d\n",
    "from utils.visualization_utils import visualize_depth, to_rgb\n",
    "from utils.transformation_utils import imgs_to_pcd, rs_ci, unnormalize_depth\n",
    "import yaml\n",
    "\n",
    "root_path = Path(\"../\")\n",
    "\n",
    "class Args:\n",
    "    model_dir = root_path / \"resources_local/models/1645621150.2234087/M_total\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "config_path = args.model_dir.parent / \"config.yml\"\n",
    "model = natsorted(args.model_dir.glob(\"*.pth\"), key=lambda f: f.stem.split('e')[1])[-1]\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "network_config = config['network_config']\n",
    "trainer_config = config['basic_trainer']\n",
    "dataset_config_yaml = config['dataset_config']\n",
    "dataset_config = BasicDataset.Config.from_config(dataset_config_yaml)\n",
    "\n",
    "path = root_path / Path(trainer_config['train_path']).parent / \"test_dataset.json\"\n",
    "files = DatasetInterface.get_files_by_path(path)\n",
    "\n",
    "net = UNet(\n",
    "    n_input_channels=dataset_config.num_in_channels(),\n",
    "    n_output_channels=1, \n",
    "    initial_channels=network_config['initial_channels'],\n",
    "    bilinear=network_config['bilinear']\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "logging.info(f'Loading model {model}')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(model, map_location=device))\n",
    "# fixes wrongly saved weights from data parallel\n",
    "# tmp_net = nn.DataParallel(net)\n",
    "# tmp_net.load_state_dict(torch.load(model, map_location=device))\n",
    "# model.unlink()\n",
    "# torch.save(tmp_net.module.state_dict(), model)\n",
    "# net.load_state_dict(torch.load(model, map_location=device))\n",
    "net.eval()\n",
    "\n",
    "logging.info('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_98648/1248045477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrs_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzv_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetInterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nPredicting image {files[idx]} ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(files), size=1).item()\n",
    "rs_rgb, rs_depth, zv_rgb, zv_depth, mask = DatasetInterface.load(files[idx])\n",
    "\n",
    "logging.info(f'\\nPredicting image {files[idx]} ...')\n",
    "\n",
    "rs_min = np.nanmin(rs_depth)\n",
    "rs_max = np.nanmax(rs_depth)\n",
    "\n",
    "set = BasicDataset.preprocess_set(\n",
    "    rs_rgb, \n",
    "    rs_depth, \n",
    "    mask, \n",
    "    zv_depth, \n",
    "    dataset_config\n",
    ")\n",
    "\n",
    "img = set['image'].unsqueeze(0)\n",
    "nan_mask = set['nan-mask'].squeeze().numpy()\n",
    "region_mask = set['region-mask'].squeeze().numpy()\n",
    "img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad() and torch.cuda.amp.autocast(enabled=network_config['amp']):\n",
    "    pred_depths = net(img)\n",
    "    pred_depth = pred_depths.squeeze().float().cpu().detach().numpy()\n",
    "\n",
    "# resize images to prediction size\n",
    "input_rgb = BasicDataset.resize(rs_rgb, dataset_config.scale)\n",
    "# input_depth = BasicDataset.resize(rs_depth, dataset_config.scale)\n",
    "input_depth = img.numpy().squeeze()[3]\n",
    "# real_depth = BasicDataset.resize(zv_depth, dataset_config.scale)\n",
    "real_depth = set['label'].numpy().squeeze()\n",
    "output_rgb = BasicDataset.resize(zv_rgb, dataset_config.scale)\n",
    "\n",
    "# undo normalization\n",
    "if dataset_config.normalize_depths:\n",
    "    input_depth = unnormalize_depth(input_depth, dataset_config.normalize_depths_min, dataset_config.normalize_depths_max)\n",
    "    pred_depth = unnormalize_depth(pred_depth, dataset_config.normalize_depths_min, dataset_config.normalize_depths_max)\n",
    "    real_depth = unnormalize_depth(real_depth, dataset_config.normalize_depths_min, dataset_config.normalize_depths_max)\n",
    "\n",
    "# blackout pixel not in mask\n",
    "print(np.nanmin(pred_depth), np.nanmax(pred_depth))\n",
    "mask = np.logical_and(nan_mask, region_mask)\n",
    "pred_depth = np.where(mask, pred_depth, np.nan)\n",
    "input_depth = np.where(mask, input_depth, np.nan)\n",
    "real_depth = np.where(mask, real_depth, np.nan)\n",
    "\n",
    "print(f\"Mean depths: Input {np.nanmean(input_depth)} Label {np.nanmean(real_depth)} Predicted {np.nanmean(pred_depth)}\")\n",
    "print(f\"Distance IT {np.nansum(np.abs(input_depth - real_depth))/ np.sum(mask)}\")\n",
    "print(f\"Distance OT {np.nansum(np.abs(pred_depth - real_depth)) / np.sum(mask)}\")\n",
    "\n",
    "pred_pcd = imgs_to_pcd(input_rgb, pred_depth, rs_ci)\n",
    "input_pcd = imgs_to_pcd(input_rgb, input_depth.astype(np.float32), rs_ci)\n",
    "output_pcd = imgs_to_pcd(output_rgb, real_depth, rs_ci)\n",
    "\n",
    "o3d.visualization.draw_geometries([input_pcd])\n",
    "o3d.visualization.draw_geometries([output_pcd])\n",
    "o3d.visualization.draw_geometries([pred_pcd])\n",
    "o3d.visualization.draw_geometries([input_pcd, output_pcd])\n",
    "o3d.visualization.draw_geometries([input_pcd, pred_pcd])\n",
    "o3d.visualization.draw_geometries([pred_pcd, output_pcd])\n",
    "\n",
    "_, axarr = plt.subplots(1, 4, figsize=(30, 10))\n",
    "axarr[0].title.set_text(\"Input\")\n",
    "axarr[0].imshow(visualize_depth(input_depth))\n",
    "axarr[1].title.set_text(\"Label\")\n",
    "axarr[1].imshow(visualize_depth(real_depth))\n",
    "axarr[2].title.set_text(\"Prediction\")\n",
    "axarr[2].imshow(visualize_depth(pred_depth))\n",
    "axarr[3].imshow(to_rgb(rs_rgb))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8ac6b8f7847e7c462e3f7405388b5cb94faacccf5869628990e3a1abaf917f9"
  },
  "kernelspec": {
   "display_name": "Python training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
